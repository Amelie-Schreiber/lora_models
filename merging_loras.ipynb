{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Karcher Means of LoRA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in lora1:\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_proj_in.alpha\n",
      "lora_unet_mid_block_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_proj_out.alpha\n",
      "lora_unet_mid_block_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "from scipy.linalg import svd\n",
    "import numpy as np\n",
    "\n",
    "# Load the LoRA tensors from .safetensors files\n",
    "with safe_open(\"fashigirl-v5.5-lora-naivae-64dim.safetensors\", framework=\"pt\", device=\"cpu\") as f:\n",
    "    lora1_tensors = {}\n",
    "    for k in f.keys():\n",
    "        lora1_tensors[k] = f.get_tensor(k)\n",
    "\n",
    "# Print the available keys\n",
    "print(\"Keys in lora1:\")\n",
    "for key in lora1_tensors.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in lora2:\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_proj_in.alpha\n",
      "lora_unet_mid_block_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_proj_out.alpha\n",
      "lora_unet_mid_block_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n"
     ]
    }
   ],
   "source": [
    "with safe_open(\"lora2.safetensors\", framework=\"pt\", device=\"cpu\") as f:\n",
    "    lora2_tensors = {}\n",
    "    for k in f.keys():\n",
    "        lora2_tensors[k] = f.get_tensor(k)\n",
    "\n",
    "# Print the available keys\n",
    "print(\"Keys in lora2:\")\n",
    "for key in lora2_tensors.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import matrix_rank, norm, qr\n",
    "from UQpy.utilities.GrassmannPoint import GrassmannPoint\n",
    "from UQpy.dimension_reduction.grassmann_manifold import GrassmannOperations\n",
    "from UQpy.utilities.distances.grassmannian_distances.AsimovDistance import AsimovDistance\n",
    "from UQpy.utilities.distances.grassmannian_distances.BinetCauchyDistance import BinetCauchyDistance\n",
    "from UQpy.utilities.distances.grassmannian_distances.FubiniStudyDistance import FubiniStudyDistance\n",
    "from UQpy.utilities.distances.grassmannian_distances.GeodesicDistance import GeodesicDistance\n",
    "from UQpy.utilities.distances.grassmannian_distances.MartinDistance import MartinDistance\n",
    "from UQpy.utilities.distances.grassmannian_distances.ProcrustesDistance import ProcrustesDistance\n",
    "from UQpy.utilities.distances.grassmannian_distances.ProjectionDistance import ProjectionDistance\n",
    "from UQpy.utilities.distances.grassmannian_distances.SpectralDistance import SpectralDistance\n",
    "\n",
    "\n",
    "def compute_karcher_mean(X1, X2, distance_metric):\n",
    "    # Check if the matrices are full rank\n",
    "    if matrix_rank(X1) != min(X1.shape) or matrix_rank(X2) != min(X2.shape):\n",
    "        raise ValueError('Input matrices are not full rank.')\n",
    "\n",
    "    # Perform the Gram-Schmidt process to get orthonormal matrices\n",
    "    Q1, _ = qr(X1)\n",
    "    Q2, _ = qr(X2)\n",
    "\n",
    "    # Define the points on the Grassmann manifold\n",
    "    X1_grassmann = GrassmannPoint(Q1)\n",
    "    X2_grassmann = GrassmannPoint(Q2)\n",
    "\n",
    "    # List of points\n",
    "    grassmann_points = [X1_grassmann, X2_grassmann]\n",
    "\n",
    "    # Define the distance measure based on user input\n",
    "    if distance_metric == 'AsimovDistance':\n",
    "        distance = AsimovDistance()\n",
    "    elif distance_metric == 'BinetCauchyDistance':\n",
    "        distance = BinetCauchyDistance()\n",
    "    elif distance_metric == 'FubiniStudyDistance':\n",
    "        distance = FubiniStudyDistance()\n",
    "    elif distance_metric == 'GeodesicDistance':\n",
    "        distance = GeodesicDistance()\n",
    "    elif distance_metric == 'MartinDistance':\n",
    "        distance = MartinDistance()\n",
    "    elif distance_metric == 'ProcrustesDistance':\n",
    "        distance = ProcrustesDistance()\n",
    "    elif distance_metric == 'ProjectionDistance':\n",
    "        distance = ProjectionDistance()\n",
    "    elif distance_metric == 'SpectralDistance':\n",
    "        distance = SpectralDistance()\n",
    "    else:\n",
    "        raise ValueError('Invalid distance metric.')\n",
    "\n",
    "    # Compute Karcher mean using StochasticGradientDescent\n",
    "    karcher_mean = GrassmannOperations.karcher_mean(\n",
    "        grassmann_points=grassmann_points,\n",
    "        optimization_method='StochasticGradientDescent',\n",
    "        distance=distance,\n",
    "        acceleration=False,\n",
    "        tolerance=0.001,\n",
    "        maximum_iterations=1000\n",
    "    )\n",
    "\n",
    "    return karcher_mean.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1881e-02, -2.8610e-02,  2.4281e-03,  ...,  9.0122e-04,\n",
      "         -1.1467e-02,  1.7441e-02],\n",
      "        [-1.1864e-02, -3.4046e-04,  2.6031e-02,  ...,  3.2623e-02,\n",
      "         -5.7182e-03, -1.9608e-02],\n",
      "        [ 1.6434e-02, -8.0490e-04,  2.4612e-02,  ..., -9.8343e-03,\n",
      "          6.9797e-05, -1.8158e-02],\n",
      "        ...,\n",
      "        [-1.9241e-02,  3.4424e-02,  1.8143e-02,  ...,  1.6022e-02,\n",
      "         -1.8692e-03, -2.4033e-02],\n",
      "        [-2.4124e-02, -3.4821e-02, -1.5358e-02,  ...,  3.0579e-02,\n",
      "          3.6102e-02, -4.0436e-03],\n",
      "        [ 2.5772e-02, -1.8509e-02, -1.0094e-02,  ..., -2.5131e-02,\n",
      "          1.3260e-02, -1.1574e-02]], dtype=torch.float16)\n",
      "[[-0.0275    0.00898  -0.02756  ...  0.02109   0.02454   0.01735 ]\n",
      " [-0.001681 -0.03345   0.014114 ... -0.01412   0.002762  0.0167  ]\n",
      " [-0.01953   0.02481   0.005184 ...  0.0335    0.008255  0.007458]\n",
      " ...\n",
      " [ 0.03305   0.0233    0.0181   ...  0.02495   0.0361   -0.01753 ]\n",
      " [-0.01171  -0.01368  -0.0298   ...  0.032     0.009254  0.03534 ]\n",
      " [ 0.01026  -0.00195   0.02707  ... -0.02975  -0.02922   0.03094 ]]\n",
      "torch.Size([32, 768])\n",
      "(64, 768)\n"
     ]
    }
   ],
   "source": [
    "print(lora1_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'])\n",
    "print(lora2_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'].numpy())\n",
    "print(lora1_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'].shape)\n",
    "print(lora2_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'].numpy().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 768)\n",
      "(64, 768)\n",
      "(64, 64)\n",
      "[[-0.16601927  0.05208861  0.12220976 ...  0.13459587 -0.25987938\n",
      "   0.00226502]\n",
      " [-0.01015164 -0.19896531 -0.09372324 ...  0.05044137  0.12135019\n",
      "   0.17535809]\n",
      " [-0.11792711  0.14660218 -0.04240003 ... -0.12304302 -0.10536765\n",
      "   0.11791925]\n",
      " ...\n",
      " [ 0.19955479  0.14011982 -0.04992667 ... -0.10905791 -0.05989728\n",
      "   0.07369256]\n",
      " [-0.0707102  -0.08189841  0.1446561  ... -0.10068816 -0.06625681\n",
      "   0.2213837 ]\n",
      " [ 0.0619578  -0.01110882 -0.13774743 ...  0.00147635  0.04940113\n",
      "   0.17591866]]\n"
     ]
    }
   ],
   "source": [
    "X1 = lora1_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'].numpy().astype(np.float64)\n",
    "X2 = lora2_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'].numpy().astype(np.float64)\n",
    "karcher_mean = compute_karcher_mean(X1, X2, 'GeodesicDistance')\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "print(karcher_mean.shape)\n",
    "print(karcher_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16601927  0.05208861  0.12220976 ...  0.13459587 -0.25987938\n",
      "   0.00226502]\n",
      " [-0.01015164 -0.19896531 -0.09372324 ...  0.05044137  0.12135019\n",
      "   0.17535809]\n",
      " [-0.11792711  0.14660218 -0.04240003 ... -0.12304302 -0.10536765\n",
      "   0.11791925]\n",
      " ...\n",
      " [ 0.19955479  0.14011982 -0.04992667 ... -0.10905791 -0.05989728\n",
      "   0.07369256]\n",
      " [-0.0707102  -0.08189841  0.1446561  ... -0.10068816 -0.06625681\n",
      "   0.2213837 ]\n",
      " [ 0.0619578  -0.01110882 -0.13774743 ...  0.00147635  0.04940113\n",
      "   0.17591866]]\n"
     ]
    }
   ],
   "source": [
    "def compute_karcher_mean_of_models(model1_path, model2_path, key):\n",
    "    # Load the tensors from the models\n",
    "    with safe_open(model1_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        model1_tensors = {}\n",
    "        for k in f.keys():\n",
    "            model1_tensors[k] = f.get_tensor(k)\n",
    "\n",
    "    with safe_open(model2_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        model2_tensors = {}\n",
    "        for k in f.keys():\n",
    "            model2_tensors[k] = f.get_tensor(k)\n",
    "\n",
    "    # Get the update weight matrices\n",
    "    X1 = model1_tensors[key].numpy().astype(np.float64)\n",
    "    X2 = model2_tensors[key].numpy().astype(np.float64)\n",
    "\n",
    "    # Compute the Karcher mean\n",
    "    try:\n",
    "        karcher_mean = compute_karcher_mean(X1, X2, 'GeodesicDistance')  # select the appropriate distance metric\n",
    "        return karcher_mean\n",
    "    except:\n",
    "        return \"Failed to compute Karcher mean\"\n",
    "\n",
    "# Specify the paths to your models and the key\n",
    "model1_path = 'fashigirl-v5.5-lora-naivae-64dim.safetensors'\n",
    "model2_path = 'lora2.safetensors'\n",
    "key = 'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'  # adjust as per your requirements\n",
    "\n",
    "# Compute the Karcher mean\n",
    "karcher_mean = compute_karcher_mean_of_models(model1_path, model2_path, key)\n",
    "print(karcher_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16601927  0.05208861  0.12220976 ...  0.13459587 -0.25987938\n",
      "   0.00226502]\n",
      " [-0.01015164 -0.19896531 -0.09372324 ...  0.05044137  0.12135019\n",
      "   0.17535809]\n",
      " [-0.11792711  0.14660218 -0.04240003 ... -0.12304302 -0.10536765\n",
      "   0.11791925]\n",
      " ...\n",
      " [ 0.19955479  0.14011982 -0.04992667 ... -0.10905791 -0.05989728\n",
      "   0.07369256]\n",
      " [-0.0707102  -0.08189841  0.1446561  ... -0.10068816 -0.06625681\n",
      "   0.2213837 ]\n",
      " [ 0.0619578  -0.01110882 -0.13774743 ...  0.00147635  0.04940113\n",
      "   0.17591866]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from safetensors import safe_open\n",
    "from scipy.linalg import svd\n",
    "import numpy as np\n",
    "\n",
    "def compute_karcher_mean_of_models(model1_path, model2_path, key):\n",
    "    # Load the tensors from the models\n",
    "    with safe_open(model1_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        model1_tensors = {k: f.get_tensor(k) for k in f.keys()}\n",
    "\n",
    "    with safe_open(model2_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        model2_tensors = {k: f.get_tensor(k) for k in f.keys()}\n",
    "\n",
    "    # Get the update weight matrices\n",
    "    X1 = model1_tensors[key].numpy().astype(np.float64)\n",
    "    X2 = model2_tensors[key].numpy().astype(np.float64)\n",
    "\n",
    "    # Compute the Karcher mean\n",
    "    try:\n",
    "        karcher_mean = compute_karcher_mean(X1, X2, 'GeodesicDistance')  # select the appropriate distance metric\n",
    "        return karcher_mean\n",
    "    except:\n",
    "        return \"Failed to compute Karcher mean\"\n",
    "\n",
    "# Specify the paths to your models and the key\n",
    "model1_path = 'fashigirl-v5.5-lora-naivae-64dim.safetensors'\n",
    "model2_path = 'lora2.safetensors'\n",
    "key = 'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'  # adjust as per your requirements\n",
    "\n",
    "# Compute the Karcher mean\n",
    "karcher_mean = compute_karcher_mean_of_models(model1_path, model2_path, key)\n",
    "print(karcher_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged key: lora_te_text_model_encoder_layers_0_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_0_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_0_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_0_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_0_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_0_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_10_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_10_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_10_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_10_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_10_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_10_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_11_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_11_mlp_fc1.lora_down.weight computed successfully.\n",
      "Failed to compute Karcher mean for key: lora_te_text_model_encoder_layers_11_mlp_fc1.lora_up.weight\n",
      "Averaged key: lora_te_text_model_encoder_layers_11_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_11_mlp_fc2.lora_down.weight computed successfully.\n",
      "Failed to compute Karcher mean for key: lora_te_text_model_encoder_layers_11_mlp_fc2.lora_up.weight\n",
      "Averaged key: lora_te_text_model_encoder_layers_11_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Failed to compute Karcher mean for key: lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_up.weight\n",
      "Averaged key: lora_te_text_model_encoder_layers_11_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Failed to compute Karcher mean for key: lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_up.weight\n",
      "Averaged key: lora_te_text_model_encoder_layers_11_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Failed to compute Karcher mean for key: lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_up.weight\n",
      "Averaged key: lora_te_text_model_encoder_layers_11_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Failed to compute Karcher mean for key: lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_up.weight\n",
      "Averaged key: lora_te_text_model_encoder_layers_1_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_1_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_1_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_1_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_1_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_1_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_2_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_2_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_2_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_2_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_2_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_2_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_3_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_3_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_3_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_3_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_3_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_3_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_4_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_4_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_4_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_4_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_4_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_4_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_5_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_5_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_5_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_5_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_5_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_5_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_6_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_6_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_6_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_6_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_6_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_6_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_7_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_7_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_7_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_7_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_7_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_7_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_8_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_8_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_8_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_8_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_8_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_8_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_9_mlp_fc1.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_mlp_fc1.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_9_mlp_fc2.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_mlp_fc2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_9_self_attn_k_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_9_self_attn_out_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_9_self_attn_q_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_te_text_model_encoder_layers_9_self_attn_v_proj.alpha\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_0_attentions_0_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_0_attentions_0_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_0_attentions_0_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_0_attentions_0_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_0_attentions_1_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_0_attentions_1_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_0_attentions_1_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_0_attentions_1_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_down_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_mid_block_attentions_0_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_mid_block_attentions_0_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_mid_block_attentions_0_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_mid_block_attentions_0_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_mid_block_attentions_0_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_2_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_2_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_2_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_2_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_0_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_0_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_1_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_1_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_proj_in.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_2_proj_in.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_proj_out.alpha\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_2_proj_out.lora_down.weight\n",
      "Failed to compute Karcher mean for key: lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.weight\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight computed successfully.\n",
      "Averaged key: lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight computed successfully.\n",
      "Karcher mean for key lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight computed successfully.\n"
     ]
    }
   ],
   "source": [
    "def compute_karcher_mean_for_all_keys(model1_path, model2_path):\n",
    "    # Load the tensors from the models\n",
    "    with safe_open(model1_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        model1_tensors = {k: f.get_tensor(k) for k in f.keys()}\n",
    "\n",
    "    with safe_open(model2_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        model2_tensors = {k: f.get_tensor(k) for k in f.keys()}\n",
    "\n",
    "    # Compute the Karcher mean for each key\n",
    "    karcher_means = {}\n",
    "    for key in model1_tensors.keys():\n",
    "        X1 = model1_tensors[key].numpy().astype(np.float64)\n",
    "        X2 = model2_tensors[key].numpy().astype(np.float64)\n",
    "        if key.endswith(\".alpha\"):\n",
    "            # Compute the usual average for keys with '.alpha' suffixes\n",
    "            karcher_means[key] = (X1 + X2) / 2\n",
    "            print(f\"Arithmetic Averaged key: {key}\")\n",
    "        else:\n",
    "            try:\n",
    "                karcher_means[key] = compute_karcher_mean(X1, X2, 'GeodesicDistance')  # select the appropriate distance metric\n",
    "                print(f\"Karcher mean for key {key} computed successfully.\")\n",
    "            except:\n",
    "                print(f\"Arithmetic Averaged key: {key}\")\n",
    "                karcher_means[key] = (X1 + X2) / 2\n",
    "\n",
    "    return karcher_means\n",
    "\n",
    "# Specify the paths to your models\n",
    "model1_path = 'fashigirl-v5.5-lora-naivae-64dim.safetensors'\n",
    "model2_path = 'lora2.safetensors'\n",
    "\n",
    "# Compute the Karcher mean for all keys\n",
    "karcher_means = compute_karcher_mean_for_all_keys(model1_path, model2_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
