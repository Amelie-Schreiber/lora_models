{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Subspace Similarity Measure for Merging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's run some code to open two `.safetensors` files storing two LoRA models named `lora1` and `lora2`, and print the keys in their dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in lora1_tensors:\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_proj_in.alpha\n",
      "lora_unet_mid_block_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_proj_out.alpha\n",
      "lora_unet_mid_block_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from safetensors import safe_open\n",
    "from scipy.linalg import svd\n",
    "import numpy as np\n",
    "\n",
    "# Load the LoRA tensors from .safetensors files\n",
    "with safe_open(\"lora1.safetensors\", framework=\"pt\", device=\"cpu\") as f:\n",
    "    lora1_tensors = {}\n",
    "    for k in f.keys():\n",
    "        lora1_tensors[k] = f.get_tensor(k)\n",
    "\n",
    "# Print the available keys\n",
    "print(\"Keys in lora1_tensors:\")\n",
    "for key in lora1_tensors.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keys in lora2_tensors:\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.alpha\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.alpha\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_up.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.alpha\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_down.weight\n",
      "lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_proj_in.alpha\n",
      "lora_unet_mid_block_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_proj_out.alpha\n",
      "lora_unet_mid_block_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.alpha\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight\n",
      "lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight\n"
     ]
    }
   ],
   "source": [
    "with safe_open(\"lora2.safetensors\", framework=\"pt\", device=\"cpu\") as f:\n",
    "    lora2_tensors = {}\n",
    "    for k in f.keys():\n",
    "        lora2_tensors[k] = f.get_tensor(k)\n",
    "\n",
    "print(\"\\nKeys in lora2_tensors:\")\n",
    "for key in lora2_tensors.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "\n",
    "# Given matrices B1, A1, B2, A2\n",
    "# B1, A1 = np.random.rand(8, 64), np.random.rand(64, 8)  # for example\n",
    "# B2, A2 = np.random.rand(64, 64), np.random.rand(64, 64)  # for example\n",
    "\n",
    "def compute_subspace_similarity(B1, A1, B2, A2, i, j):\n",
    "    # Perform SVD to get the right singular unitary matrices\n",
    "    _, _, U_A1 = svd(A1)\n",
    "    _, _, U_A2 = svd(A2)\n",
    "\n",
    "    # Take the first i and j singular vectors\n",
    "    U_A1_i = U_A1[:, :i]\n",
    "    U_A2_j = U_A2[:, :j]\n",
    "\n",
    "    # Compute the Frobenius norm\n",
    "    norm = np.linalg.norm(U_A1_i.T @ U_A2_j, 'fro')**2\n",
    "\n",
    "    # Normalize by min(i, j)\n",
    "    normalized_norm = norm / min(i, j)\n",
    "\n",
    "    return normalized_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity = compute_subspace_similarity(B1, A1, B2, A2, 3, 5)\n",
    "# print(\"Similarity:\", similarity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the paper on LoRAs, the following concept is introduced: The subspace similarity measure is a way of measuring the similarity between the subspaces spanned by the top singular vectors of two low-rank adaptation matrices, $A_{r=8}$ and $A_{r=64}$, from the same pre-trained model. Here's how it's done:\n",
    "\n",
    "First, you perform a singular value decomposition (SVD) on each of these matrices to obtain their right-singular unitary matrices, denoted $U_{A_{r=8}}$ and $U_{A_{r=64}}$.\n",
    "\n",
    "The goal is then to quantify how much of the subspace spanned by the top $i$ singular vectors in $U_{A_{r=8}}$ is contained in the subspace spanned by the top $j$ singular vectors of $U_{A_{r=64}}$.\n",
    "\n",
    "This is measured using a normalized subspace similarity based on the Grassmann distance. The formula for this measure, denoted $\\phi(A_{r=8}, A_{r=64}, i, j)$, is given as follows:\n",
    "\n",
    "$$\n",
    "\\phi(A_{r=8}, A_{r=64}, i, j) = \\frac{||U_{A_{r=8}}^{(i)} {U_{A_{r=64}}^{(j)}}^T||_F^2}{\\min(i, j)}\n",
    "$$\n",
    "\n",
    "where $U_{A_{r}}^{(i)}$ represents the columns of $U_{A_{r}}$ corresponding to the top $i$ singular vectors, and $||\\cdot||_F$ denotes the Frobenius norm.\n",
    "\n",
    "The measure $\\phi(·)$ ranges from 0 to 1, where 1 represents a complete overlap of the subspaces (i.e., they are the same), and 0 represents a complete separation (i.e., they are orthogonal). This is a normalized measure because it's divided by $\\min(i, j)$, which is the maximum possible square of the Frobenius norm of the product matrix $U_{A_{r=8}}^{(i)} {U_{A_{r=64}}^{(j)}}^T$.\n",
    "\n",
    "This process is performed for all pairs $(i, j)$ where $1 \\leq i \\leq 8$ and $1 \\leq j \\leq 64$. The results give an understanding of how much the learned subspaces for different ranks overlap with each other.\n",
    "\n",
    "This can also be performed on two layers $\\Delta W_1 = B_1A_1$ and $\\Delta W_2 = B_2A_2$  in two different LoRAs. In particular, suppose we choose a layer `n` of each LoRA and run the subspace similarity measure comparison on $U_{\\Delta W_1}^{(i)} {U_{\\Delta W_2}^{(j)}}^T$. Then this will tell us how much those to LoRAs overlap with one another. \n",
    "\n",
    "This could be useful in determining which LoRAs to merge. If we run this analysis on all of the weight matrices of two different LoRAs, then we can determine how much layer `n` of `lora1` overlaps with layer `n` of `lora2`. If the overlap is small, then the two weight martices $\\Delta W_1^{(n)} = B_1^{(n)}A_1^{(n)}$ and $\\Delta W_2^{(n)} = B_2^{(n)}A_2^{(n)}$ may express very different things because the subspaces that they span do not overlap very much. So, to be more explicit, we compute\n",
    "\n",
    "$$\n",
    "\\phi(\\Delta W_1^{(n)}, \\Delta W_2^{(n)}, i, j) = \\frac{||U_{\\Delta W_1^{(n)}}^{(i)} {U_{\\Delta W_2^{(n)}}^{(j)}}^T||_F^2}{\\min(i, j)}\n",
    "$$\n",
    "\n",
    "for a weight matrix $\\Delta W_1$ from the first LoRA, and the corresponding $\\Delta W_2$ from the second LoRA. This could indicate that merging the two LoRAs will create a more general model, able to create a wider range of diverse styles. This might also help in explaining why two LoRAs create something very muddy or undesirable when merges. Obviously, this is all conjecture based on a mathematical analysis that needs to be tested, and it does not provide a precise theshold for the overlap. What upper or lower bound might we use for this subspace similarity measure $\\phi$? Could this hypthesis be wrong, or inverted? That is, is it possible that in some cases we actually want *high* overlap between models so that we merge very similar concepts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subspace similarity measure is: 0.26528483629226685\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# The A matrices\n",
    "A1 = lora1_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'].float()\n",
    "A2 = lora2_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'].float()\n",
    "\n",
    "# The B matrices\n",
    "B1 = lora1_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight'].float()\n",
    "B2 = lora2_tensors['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight'].float()\n",
    "\n",
    "# Compute the update matrices\n",
    "Delta_W1 = torch.matmul(B1, A1)\n",
    "Delta_W2 = torch.matmul(B2, A2)\n",
    "\n",
    "# Compute the SVD of the update matrices\n",
    "U1, _, _ = torch.svd(Delta_W1)\n",
    "U2, _, _ = torch.svd(Delta_W2)\n",
    "\n",
    "# Define the subspace similarity measure\n",
    "def phi(U1, U2, i, j):\n",
    "    U1_i = U1[:, :i]  # First i columns of U1\n",
    "    U2_j = U2[:, :j]  # First j columns of U2\n",
    "    \n",
    "    product = torch.matmul(U1_i.t(), U2_j)  # Matrix multiplication\n",
    "    norm = torch.norm(product)  # Frobenius norm\n",
    "    \n",
    "    return norm ** 2 / min(i, j)\n",
    "\n",
    "# Calculate the subspace similarity measure\n",
    "i = U1.size(1)  # Number of columns in U1\n",
    "j = U2.size(1)  # Number of columns in U2\n",
    "result = phi(U1, U2, i, j)  # Replace i and j with the desired values\n",
    "\n",
    "print(f'The subspace similarity measure is: {result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subspace similarity measure for layer 0 is: 0.26528483629226685\n",
      "The subspace similarity measure for layer 1 is: 0.26683029532432556\n",
      "The subspace similarity measure for layer 2 is: 0.27087515592575073\n",
      "The subspace similarity measure for layer 3 is: 0.2644103169441223\n",
      "The subspace similarity measure for layer 4 is: 0.2637903094291687\n",
      "The subspace similarity measure for layer 5 is: 0.2647744119167328\n",
      "The subspace similarity measure for layer 6 is: 0.26757362484931946\n",
      "The subspace similarity measure for layer 7 is: 0.26692089438438416\n",
      "The subspace similarity measure for layer 8 is: 0.26369643211364746\n",
      "The subspace similarity measure for layer 9 is: 0.2677040100097656\n",
      "The subspace similarity measure for layer 10 is: 0.26571375131607056\n",
      "The subspace similarity measure for layer 11 is: 0.28491613268852234\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Number of layers in your LoRAs\n",
    "# num_layers = len(lora1_tensors.keys()) // 2  # Assuming that each layer has a down and up weight\n",
    "num_layers = 12\n",
    "\n",
    "# Define the subspace similarity measure\n",
    "def phi(U1, U2, i, j):\n",
    "    U1_i = U1[:, :i]  # First i columns of U1\n",
    "    U2_j = U2[:, :j]  # First j columns of U2\n",
    "    \n",
    "    product = torch.matmul(U1_i.t(), U2_j)  # Matrix multiplication\n",
    "    norm = torch.norm(product)  # Frobenius norm\n",
    "    \n",
    "    return norm ** 2 / min(i, j)\n",
    "\n",
    "# Iterate over all layers\n",
    "for layer in range(num_layers):\n",
    "    # Extract the corresponding A and B matrices\n",
    "    A1 = lora1_tensors[f'lora_te_text_model_encoder_layers_{layer}_mlp_fc1.lora_down.weight'].float()\n",
    "    B1 = lora1_tensors[f'lora_te_text_model_encoder_layers_{layer}_mlp_fc1.lora_up.weight'].float()\n",
    "    \n",
    "    A2 = lora2_tensors[f'lora_te_text_model_encoder_layers_{layer}_mlp_fc1.lora_down.weight'].float()\n",
    "    B2 = lora2_tensors[f'lora_te_text_model_encoder_layers_{layer}_mlp_fc1.lora_up.weight'].float()\n",
    "\n",
    "    # Compute the update matrices\n",
    "    Delta_W1 = torch.matmul(B1, A1)\n",
    "    Delta_W2 = torch.matmul(B2, A2)\n",
    "\n",
    "    # Compute the SVD of the update matrices\n",
    "    U1, _, _ = torch.svd(Delta_W1)\n",
    "    U2, _, _ = torch.svd(Delta_W2)\n",
    "\n",
    "    # Calculate the subspace similarity measure\n",
    "    i = U1.size(1)  # Number of columns in U1\n",
    "    j = U2.size(1)  # Number of columns in U2\n",
    "    result = phi(U1, U2, i, j)  # Replace i and j with the desired values\n",
    "\n",
    "    print(f'The subspace similarity measure for layer {layer} is: {result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 0 is: 0.26528483629226685\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 1 is: 0.9999878406524658\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 2 is: 0.9999885559082031\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 3 is: 0.9999887347221375\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 4 is: 0.9999908804893494\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 5 is: 0.9999882578849792\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 6 is: 0.26571375131607056\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 7 is: 0.999989926815033\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 8 is: 0.9999870657920837\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 9 is: 0.9999893307685852\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 10 is: 0.9999907612800598\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 11 is: 0.9999897480010986\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 12 is: 0.28491613268852234\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 13 is: 0.9999805092811584\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 14 is: 0.9999852180480957\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 15 is: 0.9999846816062927\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 16 is: 0.9999852180480957\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 17 is: 0.9999863505363464\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 18 is: 0.26683029532432556\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 19 is: 0.9999917149543762\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 20 is: 0.9999911785125732\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 21 is: 0.9999918341636658\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 22 is: 0.999991238117218\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 23 is: 0.9999890923500061\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 24 is: 0.27087515592575073\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 25 is: 0.9999900460243225\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 26 is: 0.9999902248382568\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 27 is: 0.9999883770942688\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 28 is: 0.9999927878379822\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 29 is: 0.9999895095825195\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 30 is: 0.2644103169441223\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 31 is: 0.9999893307685852\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 32 is: 0.9999906420707703\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 33 is: 0.9999896883964539\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 34 is: 0.9999893307685852\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 35 is: 0.9999897480010986\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 36 is: 0.2637903094291687\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 37 is: 0.9999907612800598\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 38 is: 0.9999885559082031\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 39 is: 0.9999929070472717\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 40 is: 0.9999893307685852\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 41 is: 0.9999902248382568\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 42 is: 0.2647744119167328\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 43 is: 0.9999902248382568\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 44 is: 0.9999925494194031\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 45 is: 0.9999881386756897\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 46 is: 0.9999892115592957\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 47 is: 0.9999880194664001\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 48 is: 0.26757362484931946\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 49 is: 0.9999914169311523\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 50 is: 0.9999897480010986\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 51 is: 0.9999881386756897\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 52 is: 0.9999889731407166\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 53 is: 0.9999887943267822\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 54 is: 0.26692089438438416\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 55 is: 0.9999887347221375\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 56 is: 0.9999871253967285\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 57 is: 0.9999900460243225\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 58 is: 0.9999880194664001\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 59 is: 0.9999917149543762\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 60 is: 0.26369643211364746\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 61 is: 0.9999907612800598\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 62 is: 0.9999887943267822\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 63 is: 0.9999917149543762\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 64 is: 0.9999876618385315\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 65 is: 0.9999878406524658\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([3072, 32])\n",
      "The subspace similarity measure for layer 66 is: 0.2677040100097656\n",
      "A1 shape: torch.Size([32, 3072])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 67 is: 0.9999887943267822\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 68 is: 0.9999882578849792\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 69 is: 0.9999876022338867\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 70 is: 0.9999895095825195\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([768, 32])\n",
      "The subspace similarity measure for layer 71 is: 0.9999914169311523\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 72: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 73: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 74 is: 0.9999980926513672\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 75 is: 0.9999991655349731\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 76 is: 1.0\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 77 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 78 is: 0.9999991655349731\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 79 is: 0.9999991655349731\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 80 is: 1.0000004768371582\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 81 is: 0.9999998211860657\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([2560, 32])\n",
      "The subspace similarity measure for layer 82 is: 0.17305810749530792\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 83 is: 1.0\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 84: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 85: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 86 is: 0.9999994039535522\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 87 is: 0.999998927116394\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 88 is: 0.9999991655349731\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 89 is: 0.9999998211860657\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 90 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 91 is: 0.9999996423721313\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 92 is: 0.9999985694885254\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 93 is: 0.9999996423721313\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([2560, 32])\n",
      "The subspace similarity measure for layer 94 is: 0.1714164912700653\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 95 is: 0.999998927116394\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 96: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 97: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 98 is: 0.9999935030937195\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 99 is: 0.9999909400939941\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 100 is: 0.9999929666519165\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 101 is: 0.9999938011169434\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 102 is: 0.9999944567680359\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 103 is: 0.9999935030937195\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 104 is: 0.999994158744812\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 105 is: 0.999994158744812\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([5120, 32])\n",
      "The subspace similarity measure for layer 106 is: 0.1543945074081421\n",
      "A1 shape: torch.Size([32, 2560])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 107 is: 0.9999948740005493\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 108: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 109: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 110 is: 0.9999915957450867\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 111 is: 0.999994158744812\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 112 is: 0.9999936819076538\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 113 is: 0.9999948740005493\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 114 is: 0.9999935030937195\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 115 is: 0.9999935030937195\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 116 is: 0.9999924898147583\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 117 is: 0.9999963641166687\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([5120, 32])\n",
      "The subspace similarity measure for layer 118 is: 0.15738140046596527\n",
      "A1 shape: torch.Size([32, 2560])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 119 is: 0.9999927282333374\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 120: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 121: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 122 is: 0.9999516606330872\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 123 is: 0.9999529123306274\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 124 is: 0.9999490976333618\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 125 is: 0.9999464750289917\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 126 is: 0.6105306148529053\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 127 is: 0.9999467134475708\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 128 is: 0.9999494552612305\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 129 is: 0.6055203080177307\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([10240, 32])\n",
      "The subspace similarity measure for layer 130 is: 0.1365688443183899\n",
      "A1 shape: torch.Size([32, 5120])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 131 is: 0.9999482035636902\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 132: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 133: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 134 is: 0.99995356798172\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 135 is: 0.9999462962150574\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 136 is: 0.9999518394470215\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 137 is: 0.999947726726532\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 138 is: 0.6102796196937561\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 139 is: 0.9999510049819946\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 140 is: 0.999951183795929\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 141 is: 0.6098781228065491\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([10240, 32])\n",
      "The subspace similarity measure for layer 142 is: 0.13769392669200897\n",
      "A1 shape: torch.Size([32, 5120])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 143 is: 0.9999533891677856\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 144: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 145: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 146 is: 0.9999492764472961\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 147 is: 0.9999454617500305\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 148 is: 0.9999492764472961\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 149 is: 0.999952495098114\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 150 is: 0.6096875667572021\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 151 is: 0.999946117401123\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 152 is: 0.9999537467956543\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 153 is: 0.6064993143081665\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([10240, 32])\n",
      "The subspace similarity measure for layer 154 is: 0.1332767903804779\n",
      "A1 shape: torch.Size([32, 5120])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 155 is: 0.9999533891677856\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 156: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 157: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 158 is: 0.9999464750289917\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 159 is: 0.9999462962150574\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 160 is: 0.9999482035636902\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 161 is: 0.9999533891677856\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 162 is: 0.607451856136322\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 163 is: 0.9999510049819946\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 164 is: 0.9999456405639648\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 165 is: 0.6084207892417908\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([10240, 32])\n",
      "The subspace similarity measure for layer 166 is: 0.13885697722434998\n",
      "A1 shape: torch.Size([32, 5120])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 167 is: 0.9999513626098633\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 168: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 169: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 170 is: 0.9999482035636902\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 171 is: 0.9999467134475708\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 172 is: 0.9999497532844543\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 173 is: 0.9999483823776245\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 174 is: 0.6065221428871155\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 175 is: 0.999950110912323\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 176 is: 0.999952495098114\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 177 is: 0.6052832007408142\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([10240, 32])\n",
      "The subspace similarity measure for layer 178 is: 0.13806910812854767\n",
      "A1 shape: torch.Size([32, 5120])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 179 is: 0.9999533891677856\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 180: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280, 1, 1])\n",
      "B1 shape: torch.Size([1280, 32, 1, 1])\n",
      "Error occurred at layer 181: The size of tensor a (32) must match the size of tensor b (1280) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 182 is: 0.9999497532844543\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 183 is: 0.999947726726532\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 184 is: 0.9999490976333618\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 185 is: 0.9999494552612305\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 186 is: 0.6104145646095276\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 187 is: 0.9999492764472961\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 188 is: 0.9999518394470215\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 189 is: 0.6065794229507446\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([10240, 32])\n",
      "The subspace similarity measure for layer 190 is: 0.13888858258724213\n",
      "A1 shape: torch.Size([32, 5120])\n",
      "B1 shape: torch.Size([1280, 32])\n",
      "The subspace similarity measure for layer 191 is: 0.9999510049819946\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 192: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 193: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 194 is: 0.999995231628418\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 195 is: 0.9999944567680359\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 196 is: 0.9999953508377075\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 197 is: 0.9999927282333374\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 198 is: 0.999996542930603\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 199 is: 0.9999920129776001\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 200 is: 0.9999912977218628\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 201 is: 0.9999947547912598\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([5120, 32])\n",
      "The subspace similarity measure for layer 202 is: 0.16359271109104156\n",
      "A1 shape: torch.Size([32, 2560])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 203 is: 0.9999944567680359\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 204: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 205: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 206 is: 0.9999931454658508\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 207 is: 0.9999938011169434\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 208 is: 0.9999936819076538\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 209 is: 0.9999963045120239\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 210 is: 0.9999942779541016\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 211 is: 0.9999939799308777\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 212 is: 0.9999924898147583\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 213 is: 0.9999938011169434\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([5120, 32])\n",
      "The subspace similarity measure for layer 214 is: 0.1611660271883011\n",
      "A1 shape: torch.Size([32, 2560])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 215 is: 0.999994158744812\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 216: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640, 1, 1])\n",
      "B1 shape: torch.Size([640, 32, 1, 1])\n",
      "Error occurred at layer 217: The size of tensor a (32) must match the size of tensor b (640) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 218 is: 0.9999934434890747\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 219 is: 0.9999917149543762\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 220 is: 0.9999934434890747\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 221 is: 0.9999942779541016\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 222 is: 0.9999932050704956\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 223 is: 0.9999909400939941\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 224 is: 0.999995231628418\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 225 is: 0.9999920129776001\n",
      "A1 shape: torch.Size([32, 640])\n",
      "B1 shape: torch.Size([5120, 32])\n",
      "The subspace similarity measure for layer 226 is: 0.16014735400676727\n",
      "A1 shape: torch.Size([32, 2560])\n",
      "B1 shape: torch.Size([640, 32])\n",
      "The subspace similarity measure for layer 227 is: 0.9999931454658508\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 228: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 229: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 230 is: 0.9999991655349731\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 231 is: 0.9999982714653015\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 232 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 233 is: 0.9999998211860657\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 234 is: 0.9999980926513672\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 235 is: 0.9999998211860657\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 236 is: 1.0\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 237 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([2560, 32])\n",
      "The subspace similarity measure for layer 238 is: 0.1775144338607788\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 239 is: 0.9999994039535522\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 240: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 241: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 242 is: 0.9999998211860657\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 243 is: 0.9999996423721313\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 244 is: 0.9999994039535522\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 245 is: 0.9999998211860657\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 246 is: 0.9999985694885254\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 247 is: 0.9999982714653015\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 248 is: 0.9999998211860657\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 249 is: 0.9999996423721313\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([2560, 32])\n",
      "The subspace similarity measure for layer 250 is: 0.18077997863292694\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 251 is: 0.999998927116394\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 252: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320, 1, 1])\n",
      "B1 shape: torch.Size([320, 32, 1, 1])\n",
      "Error occurred at layer 253: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 1\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 254 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 255 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 256 is: 1.0\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 257 is: 0.9999998211860657\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 258 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 259 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 260 is: 0.9999987483024597\n",
      "A1 shape: torch.Size([32, 768])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 261 is: 0.999998927116394\n",
      "A1 shape: torch.Size([32, 320])\n",
      "B1 shape: torch.Size([2560, 32])\n",
      "The subspace similarity measure for layer 262 is: 0.17570427060127258\n",
      "A1 shape: torch.Size([32, 1280])\n",
      "B1 shape: torch.Size([320, 32])\n",
      "The subspace similarity measure for layer 263 is: 0.9999998211860657\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Gather all keys and sort them\n",
    "all_keys = sorted(list(lora1_tensors.keys()))\n",
    "\n",
    "# Filter keys for lora_down and lora_up pairs\n",
    "lora_down_keys = [key for key in all_keys if 'lora_down' in key]\n",
    "lora_up_keys = [key for key in all_keys if 'lora_up' in key]\n",
    "\n",
    "# Ensure we have matching pairs of keys\n",
    "assert len(lora_down_keys) == len(lora_up_keys), \"Mismatch in number of 'lora_down' and 'lora_up' keys\"\n",
    "\n",
    "# Define the subspace similarity measure\n",
    "def phi(U1, U2, i, j):\n",
    "    U1_i = U1[:, :i]  # First i columns of U1\n",
    "    U2_j = U2[:, :j]  # First j columns of U2\n",
    "    \n",
    "    product = torch.matmul(U1_i.t(), U2_j)  # Matrix multiplication\n",
    "    norm = torch.norm(product)  # Frobenius norm\n",
    "    \n",
    "    return norm ** 2 / min(i, j)\n",
    "\n",
    "# Iterate over all layers\n",
    "for layer in range(len(lora_down_keys)):\n",
    "    try:\n",
    "        # Extract the corresponding A and B matrices\n",
    "        A1 = lora1_tensors[lora_down_keys[layer]].float()\n",
    "        B1 = lora1_tensors[lora_up_keys[layer]].float()\n",
    "\n",
    "        A2 = lora2_tensors[lora_down_keys[layer]].float()\n",
    "        B2 = lora2_tensors[lora_up_keys[layer]].float()\n",
    "\n",
    "        # Print the shapes of A1 and B1 matrices for troubleshooting\n",
    "        print(f\"A1 shape: {A1.shape}\")\n",
    "        print(f\"B1 shape: {B1.shape}\")\n",
    "\n",
    "        # Compute the update matrices\n",
    "        Delta_W1 = torch.matmul(B1, A1)\n",
    "        Delta_W2 = torch.matmul(B2, A2)\n",
    "\n",
    "        # Compute the SVD of the update matrices\n",
    "        U1, _, _ = torch.svd(Delta_W1)\n",
    "        U2, _, _ = torch.svd(Delta_W2)\n",
    "\n",
    "        # Calculate the subspace similarity measure\n",
    "        i = U1.size(1)  # Number of columns in U1\n",
    "        j = U2.size(1)  # Number of columns in U2\n",
    "        result = phi(U1, U2, i, j)  # Replace i and j with the desired values\n",
    "\n",
    "        print(f\"The subspace similarity measure for layer {layer} is: {result}\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        # Print the layer number and the error message\n",
    "        print(f\"Error occurred at layer {layer}: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this down once more. \n",
    "\n",
    "From the above code, we see that many of the update matrices overlap quite a lot, but some have a much smaller overlap. How can we better understand how many of the overlaps contribute to a more general or expressive model? In other words, if a significant portion of the update matrices have high (or low) overlap, what does this mean, and what number or porportion of the update matrices can we call \"significant\" in this case?\n",
    "\n",
    "LoRA (Low-Rank Adaptation) is a technique used to fine-tune large language models with a significantly lower computational cost compared to traditional methods. The key idea behind LoRA is to restrict the updates during the fine-tuning process to a low-rank subspace of the parameter space.\n",
    "\n",
    "Given a large pre-trained model with parameters $\\Theta$, LoRA introduces two sets of new parameters $A$ and $B$ such that the updates to the parameters of the model during fine-tuning can be written as $\\Delta W = BA$, where $A \\in \\mathbb{R}^{k \\times m}$ and $B \\in \\mathbb{R}^{n \\times k}$, $n$ is the number of parameters in the layer, $m$ is the size of the context window, and $k$ is the rank of the low-rank update, typically much smaller than $n$ and $m$. This formulation ensures that the updates $\\Delta W$ lie in a $k$-dimensional subspace of the parameter space.\n",
    "\n",
    "The code provided above computes a subspace similarity metric between pairs of update matrices in two different LoRA models. Specifically, for each layer $n$ in the models, it computes the update matrices $\\Delta W_1^{(n)} = B_1^{(n)}A_1^{(n)}$ and $\\Delta W_2^{(n)} = B_2^{(n)}A_2^{(n)}$ and then calculates the similarity between the subspaces spanned by $\\Delta W_1^{(n)}$ and $\\Delta W_2^{(n)}$. \n",
    "\n",
    "The subspace similarity metric $\\phi$ is computed as follows:\n",
    "\n",
    "$$\n",
    "\\phi(\\Delta W_1, \\Delta W_2, i, j) = \\frac{||U_{\\Delta W_1^{(n)}}^{(i)} {U_{\\Delta W_2^{(n)}}^{(j)}}^T||_F^2}{\\min(i, j)}\n",
    "$$\n",
    "\n",
    "Here, $U_{\\Delta W_1^{(n)}}^{(i)}$ and $U_{\\Delta W_2^{(n)}}^{(j)}$ are the first $i$ and $j$ left singular vectors of $\\Delta W_1^{(n)}$ and $\\Delta W_2^{(n)}$, respectively, obtained through singular value decomposition. The operator $||\\cdot||_F$ denotes the Frobenius norm, and $\\min(i, j)$ ensures the normalization of the metric to the smaller dimension of the two subspaces.\n",
    "\n",
    "This metric $\\phi$ effectively measures how aligned the two subspaces are. If the two subspaces are similar, their corresponding left singular vectors will be closely aligned, leading to a large Frobenius norm of their product, and thus a large value of $\\phi$. Conversely, if the subspaces are dissimilar, their left singular vectors will not align well, resulting in a smaller Frobenius norm and a smaller $\\phi$.\n",
    "\n",
    "This is related to the Grassmann manifold because the set of all $k$-dimensional subspaces of an $n$-dimensional vector space forms a Grassmann manifold $G(n, k)$. The metric $\\phi$ can be viewed as a measure of distance on this manifold, allowing us to quantify the difference between the subspaces spanned by the updates of different LoRA models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interpreting the subspace similarity metric, a high value (like 0.99 or above) indicates that the corresponding update matrices (and hence the associated subspaces) of the two LoRA models are very similar or aligned. This suggests that the two models are learning very similar \"concepts\" or features.\n",
    "\n",
    "In the context of a text-to-vision model like DALL-E or StableDiffusion, this might mean that the two LoRA models are both focusing on the same kind of visual or textual features in the data, and making similar updates during training to capture these features. If these models are meant to learn different concepts or tasks, this high similarity might indicate that they are failing to differentiate between these tasks and are instead learning similar representations.\n",
    "\n",
    "Conversely, a low value (like 0.25 or below) of the subspace similarity metric indicates that the corresponding update matrices of the two models are quite different or unaligned. This suggests that the two models are learning different \"concepts\" or features.\n",
    "\n",
    "Again, in the context of a text-to-vision model, this might mean that the two LoRA models are focusing on different kinds of visual or textual features in the data, and making different updates during training to capture these features. If these models are meant to learn different concepts or tasks, this low similarity could be a good sign that they are successfully differentiating between these tasks and learning distinct representations.\n",
    "\n",
    "Of course, these interpretations are only rough indications and might not capture the full complexity of what's happening in the models. It's also important to remember that the subspace similarity metric is just one of many ways to measure the similarity between models, and it might not always reflect the actual functional or semantic similarity between the models. For a more comprehensive understanding of what the models are learning, you would likely need to use a combination of different analysis techniques, including both quantitative measures like the subspace similarity metric and qualitative methods like visual inspection of the generated outputs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging two models that have high subspace overlaps for a significant portion of their update matrices can be a challenging task. The high overlap suggests that the models are learning similar features or concepts, so simply averaging the update matrices might not result in a meaningful combination of the models' knowledge.\n",
    "\n",
    "One way to merge the models might be to use a weighted average of the update matrices, where the weights are determined based on some measure of the models' performance or relevance to the task at hand. For instance, if one model performs better on a validation set or is known to be more relevant to the task, you could assign it a higher weight. This would give more influence to the better or more relevant model in the merged model.\n",
    "\n",
    "However, this approach assumes that the models' update matrices can be meaningfully averaged, which might not be the case if the models are learning very different features or concepts, or if their update matrices lie in different parts of the parameter space.\n",
    "\n",
    "If the models' update matrices are very close together in the Grassmann manifold (i.e., they have high subspace overlap), and you want to push them further apart, you might need to modify the models' training process to encourage them to learn more diverse features or concepts. This could be done by adding a regularization term to the loss function that penalizes similarity between the models' update matrices, effectively pushing their subspaces apart in the Grassmann manifold.\n",
    "\n",
    "Such a regularization term could be based on the subspace similarity metric itself, or on some other measure of similarity between the update matrices. The exact form of the regularization term would depend on the specific characteristics of your models and your training setup, and would likely require some experimentation to find the best approach.\n",
    "\n",
    "It's worth noting that pushing the models' update matrices further apart in the Grassmann manifold is not always desirable. If the models are learning similar features or concepts because these are important for the task at hand, forcing them to diverge might hurt their performance. It's important to carefully consider the implications of pushing the models apart before deciding to implement such a strategy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the regularization term to push the subspaces apart can be inappropriate in a few scenarios:\n",
    "\n",
    "1. **Shared Essential Features**: If the models are learning similar features because these features are fundamental or essential for the task at hand, forcing the models to diverge might result in them missing out on these essential features, thereby hurting their performance.\n",
    "\n",
    "2. **Task Similarity**: If the models are designed to solve very similar tasks, or tasks with a high degree of overlap, pushing the subspaces apart may not make sense. In this case, the models might naturally learn similar representations, and forcing divergence could lead to less optimal solutions.\n",
    "\n",
    "3. **Increased Complexity**: Adding a regularization term to push the subspaces apart increases the complexity of the model and the training process. If the benefits of divergence (e.g., increased diversity of learned features) do not outweigh the costs (e.g., increased computational resources, potential for overfitting), it may not be appropriate to use this approach.\n",
    "\n",
    "4. **Model Interpretability**: Adding a subspace divergence term could make the model more difficult to interpret, as it's another factor influencing the learning process that needs to be accounted for when analyzing the model's behavior. If interpretability is a key concern, it may be inappropriate to add this complexity.\n",
    "\n",
    "5. **Lack of Evidence for Improvement**: If there's no empirical evidence or theoretical justification suggesting that pushing the subspaces apart will improve the performance of the models on the task at hand, it might be inappropriate to use this approach. It's generally recommended to have a clear hypothesis or rationale for any changes made to the model or training process.\n",
    "\n",
    "These are general guidelines, and the specifics will depend on the particular use case, the models being used, and the tasks they're designed to solve. It's always important to carefully consider the potential implications and trade-offs of any changes to the model or training process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explain how we might train muliple LoRA models so that there is a minimal amount of overlap between each pair of models. \n",
    "\n",
    "1. We want to train multiple LoRA models simultaneously such that their update matrices are as orthogonal as possible in the Grassmann manifold. This is to ensure that they capture different directions of the loss landscape, leading to a more expressive ensemble of models.\n",
    "\n",
    "2. The similarity between two update matrices $\\Delta W^{(n)}_i$ and $\\Delta W^{(n)}_j$ from different models $i$ and $j$ can be measured using the subspace similarity metric $\\phi(\\Delta W_i, \\Delta W_j, k, l)$ defined as follows:\n",
    "\n",
    "$$\n",
    "\\phi(\\Delta W_i, \\Delta W_j, k, l) = \\frac{\\left\\|U_{\\Delta W_i^{(n)}}^{(k)} {U_{\\Delta W_j^{(n)}}^{(l)}}^T\\right\\|_F^2}{\\min(k, l)}\n",
    "$$\n",
    "\n",
    "where $U_{\\Delta W_i^{(n)}}^{(k)}$ and $U_{\\Delta W_j^{(n)}}^{(l)}$ are the left singular vectors of the SVD of the update matrices, and $\\|\\cdot\\|_F$ is the Frobenius norm.\n",
    "\n",
    "3. The loss function to encourage the update matrices to be orthogonal can be defined as the negative sum of the squared subspace similarity metrics for all pairs of models:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = -\\sum_{i \\neq j} \\phi(\\Delta W_i, \\Delta W_j, k, l)^2\n",
    "$$\n",
    "\n",
    "This loss function is minimized when the update matrices are orthogonal in the Grassmann manifold (i.e., the subspace similarity metric is zero).\n",
    "\n",
    "4. The models can be trained using gradient descent or some other optimization method, where the gradients of the loss function with respect to the parameters of the models are computed and used to update the parameters. The gradients can be computed using automatic differentiation.\n",
    "\n",
    "5. Note that the computational complexity of this process is $O(n^2)$ for $n$ models due to the pairwise similarity computation, and the optimization process can be tricky due to the interdependence of the updates to different models.\n",
    "\n",
    "6. The choice of $k$ and $l$ can be important and might need to be adjusted depending on the specific properties of your models and data.\n",
    "\n",
    "The dimension `r` of a LoRA model determines the rank of the learned update matrices and consequently the dimensionality of the subspace that they span in the Grassmann manifold. If `r` is very low (it is shown that `r=8` is more than sufficient to retain accuracy), it means that the update matrices (and hence the corresponding points in the Grassmann manifold) live in a low-dimensional subspace.\n",
    "\n",
    "This low-dimensionality has several important implications for the training process described above:\n",
    "\n",
    "1. **Computational Efficiency**: The computation of the subspace similarity metric and the corresponding loss function becomes more efficient. The singular value decomposition (SVD) used in the computation of the subspace similarity metric scales with the size of the matrices involved, so smaller matrices lead to faster computations. This makes it feasible to compute these quantities for a large number of models and update steps.\n",
    "\n",
    "2. **Simpler Optimization Landscape**: As the dimensionality of the update matrices decreases, the complexity of the optimization problem decreases as well. This can potentially make it easier to find good solutions, although the problem remains non-trivial due to the interdependence of the updates for different models.\n",
    "\n",
    "3. **More Orthogonality**: With a smaller `r`, there is a greater chance of achieving more orthogonality between the models, as there are fewer dimensions for them to overlap in. This could potentially lead to a more diverse set of models, as they are forced to learn different aspects of the data.\n",
    "\n",
    "4. **Less Overfitting**: Since the number of trainable parameters is small, the models are less likely to overfit the training data. This could potentially improve their generalization performance.\n",
    "\n",
    "However, it's important to note that a smaller `r` also means that each individual model is less expressive, as it can only capture a low-rank approximation of the gradient of the loss function. This limitation could potentially be offset by the increased diversity of the ensemble of models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Approach to Merging\n",
    "\n",
    "*Suppose we are are studying the update weight matrices $\\Delta W_1^{(n)} = B_1^{(n)}A_1^{(n)}$ for layer `n`of a reference LoRA model (Low Rank Adaptation) named `lora1.safetensors` or just `lora1`. Suppose further we have a second LoRA named `lora2` (also stored as a .safetensors file) with update weight matrices $\\Delta W_2^{(n)} = B_2^{(n)}A_2^{(n)}$. Now, define a subspace similarity metric \n",
    "\n",
    "$$\\phi(\\Delta W_i, \\Delta W_j, k, l) = \\frac{\\left\\|U_{\\Delta W_i^{(n)}}^{(k)} {U_{\\Delta W_j^{(n)}}^{(l)}}^T\\right\\|_F^2}{\\min(k, l)}$$ \n",
    "\n",
    "that helps us measure how far apart two update weight matrices are in the. Now please explain how this related to points in the Grassmannian (or on the \"Grassmann manifold\"). Please explain how the Grassmannian is realized as a quotient space (a homogeneous space) in terms of orthogonal groups. Please also explain how we might use this to define and study the equivalence classes of matrices corresponding to the update weight matrices of the two LoRA models. Please also explain how we might use this to replace to update weight matrices of `lora2` with equivalent matrices. How will these new matrices compare in the subspace similarity metric $\\phi(\\Delta W_i, \\Delta W_j, k, l)$ we defined? If we wish to merge the two LoRA models in some way, how can we use the theory and properties of the Grassmannian to do so?*\n",
    "\n",
    "Let's start by discussing the Grassmannian, a space that parametrizes all k-dimensional subspaces in an n-dimensional vector space. The Grassmannian, often denoted as G(k, n), can be thought of as a set of points, each representing a unique k-dimensional subspace in n-dimensional space.\n",
    "\n",
    "The Grassmannian is realized as a quotient space (a homogeneous space) in terms of orthogonal groups as follows: An orthogonal group, O(n), is the group of all orthogonal n×n matrices (those that preserve the dot product in Euclidean space). It includes rotations and reflections. The special orthogonal group, SO(n), is the subgroup consisting of rotations only. The Stiefel manifold, V(k, n), is the space of all orthonormal k-frames in R^n, which is a subset of O(n). It can be thought of as the space of all ordered sets of k orthogonal unit vectors in R^n.\n",
    "\n",
    "When we mod out the Stiefel manifold by the action of the orthogonal group O(k) (the group of all orthogonal k×k matrices), we get the Grassmannian. In other words, the Grassmannian G(k, n) is the quotient space V(k, n) / O(k). The action of O(k) on V(k, n) is to change the basis of each k-subspace in R^n without changing the subspace itself. Hence, each point in the Grassmannian represents an equivalence class of k-frames that span the same k-subspace in R^n.\n",
    "\n",
    "Now, let's relate this to the problem involving the update weight matrices of the two LoRA models.\n",
    "\n",
    "In your context, the update weight matrices ΔW_i^(n) and ΔW_j^(n) correspond to linear transformations in some high-dimensional space. The subspaces of interest here are the column spaces of these matrices. The subspace similarity metric φ(ΔW_i, ΔW_j, k, l) measures how \"close\" these column spaces are to each other in terms of their principal subspaces spanned by the first k and l singular vectors respectively. This notion of \"closeness\" can be thought of as a distance in the Grassmannian.\n",
    "\n",
    "When you talk about replacing the update weight matrices of lora2 with \"equivalent\" matrices, you're essentially discussing a change of basis within each subspace. In terms of the Grassmannian, you're moving within an equivalence class. The subspace similarity metric φ(ΔW_i, ΔW_j, k, l) should remain the same, because the metric is a function of the subspaces themselves, not the specific bases (i.e., matrices) that you choose to represent them.\n",
    "\n",
    "If you wish to \"merge\" the two LoRA models, one possibility could be to find a common subspace that best represents the column spaces of both models' update weight matrices. This common subspace can be thought of as a point in the Grassmannian that is \"close\" to the points representing the column spaces of both models. How exactly to find such a common subspace would depend on the specifics of your problem, but in general, you could use techniques such as principal angles (canonical correlations) or other Grassmannian-based optimization methods to do this. \n",
    "\n",
    "The Grassmannian's geometry and algebraic structure (e.g., its topology as a homogeneous space and its structure as a manifold) can provide a rich mathematical framework for studying these kinds of problems in machine learning.\n",
    "\n",
    "*Let's discuss the merging process more. How might one create a third LoRA model `lora3`, that have update weight matrices $\\Delta W_3^{(n)} = B_3^{(n)}A_3^{(n)}$ that has maximum overlap with both $\\Delta W_1^{(n)} = B_1^{(n)}A_1^{(n)}$ and $\\Delta W_2^{(n)} = B_2^{(n)}A_2^{(n)}$ for each layer `n`? That is, so that each $\\Delta W_3^{(n)}$ is close to $\\Delta W_1^{(n)}$ and $\\Delta W_2^{(n)}$ in the Grassmannian manifold for all $n$?*\n",
    "\n",
    "One approach to creating a third LoRA model `lora3` that has maximum overlap with both `lora1` and `lora2` is to find a common subspace for each layer `n` that is close to the subspaces represented by ΔW_1^(n) and ΔW_2^(n) in the Grassmannian manifold. This could be achieved by solving an optimization problem that minimizes the distance (in terms of the subspace similarity metric φ) between the column spaces of ΔW_3^(n), ΔW_1^(n), and ΔW_2^(n). \n",
    "\n",
    "This optimization problem can be formalized as:\n",
    "\n",
    "Minimize: $\\phi(\\Delta W_3^{(n)}, \\Delta W_1^{(n)}, k, l) + \\phi(\\Delta W_3^{(n)}, \\Delta W_2^{(n)}, k, l)$\n",
    "Subject to: $\\Delta W_3^{(n)} = B_3^{(n)}A_3^{(n)}$\n",
    "\n",
    "Here, $B_3^{(n)}$ and $A_3^{(n)}$ are weight matrices that need to be determined. \n",
    "\n",
    "The minimization can be done using gradient descent or other optimization techniques, where the gradient of the objective function can be computed using the properties of the Grassmannian manifold.\n",
    "\n",
    "This method would give you a new set of weight matrices for `lora3` that represent a common subspace for each layer `n`, which is close to the subspaces represented by `lora1` and `lora2`.\n",
    "\n",
    "However, keep in mind that this process might not always yield a meaningful or useful model, because the common subspace that minimizes the distance might not preserve the essential features that `lora1` and `lora2` have learned.\n",
    "\n",
    "Also note that this is a somewhat simplified approach and does not take into account the structure of the neural network models or the nature of the data they have been trained on. In practice, creating a merged model that performs well might involve more complex techniques, like transfer learning or knowledge distillation, and might require a careful examination of the models' architectures and training histories."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yet Another Approach Using the Plücker Embedding of the Grassmannian Manifold\n",
    "\n",
    "The Plücker embedding is a map from the Grassmannian G(k, n) into the projective space P^(N-1), where N is the binomial coefficient \"n choose k\". The Plücker coordinates of a k-dimensional subspace V of n-dimensional space are defined as the wedge products of the vectors spanning V. If the vectors are the columns of a matrix, then the Plücker coordinates are the determinants of all kxk submatrices.\n",
    "\n",
    "Let's say that $\\Delta W_1$ and $\\Delta W_2$ are two matrices whose columns span the subspaces represented by points p1 and p2 in the Grassmannian. You want to find the midpoint of the geodesic connecting p1 and p2.\n",
    "\n",
    "The Plücker embedding represents each subspace (each matrix) as a point in projective space. In this space, the geodesic between p1 and p2 is a straight line. Therefore, the midpoint of the geodesic is simply the arithmetic mean of the Plücker coordinates of p1 and p2. \n",
    "\n",
    "However, there's a caveat: The Plücker coordinates of a point in the Grassmannian satisfy certain relations called the Plücker relations, which are a consequence of the alternating property of the wedge product. The sum of two sets of Plücker coordinates might not satisfy these relations. Therefore, after computing the mean of the Plücker coordinates of p1 and p2, you need to project this point back onto the Grassmannian, i.e., find the point in the Grassmannian that is closest to the mean point under the Fubini-Study metric.\n",
    "\n",
    "This projection step is nontrivial. It requires solving an optimization problem that minimizes the distance from the mean point to the Grassmannian, subject to the Plücker relations. The result will be the Plücker coordinates of the midpoint of the geodesic.\n",
    "\n",
    "To find a matrix representation of this midpoint subspace, you would need to find a set of vectors whose wedge products give the Plücker coordinates of the midpoint. This is also a nontrivial problem, but in some cases it might be possible to solve it by using techniques from linear algebra or combinatorics.\n",
    "\n",
    "Keep in mind that this is a high-level description of the process, and the actual computations might be quite complex, especially for large values of k and n. This approach is more commonly used in theoretical studies than in practical computations. For practical purposes, other methods such as optimization on the Grassmannian might be more efficient.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's consider a simple example where we are dealing with 2-dimensional subspaces of a 4-dimensional space. This corresponds to the Grassmannian $G(2,4)$. The Plücker coordinates in this case are given by $2 \\times 2$ determinants, and there are six Plücker coordinates for each point in $G(2,4)$.\n",
    "\n",
    "Let's consider two $2 \\times 4$ matrices $\\Delta W_1$ and $\\Delta W_2$ that represent these subspaces:\n",
    "\n",
    "$$\\Delta W_1 = \\begin{bmatrix} 1 & 2 & 3 & 4 \\\\ 5 & 6 & 7 & 8 \\end{bmatrix}$$\n",
    "$$\\Delta W_2 = \\begin{bmatrix} -1 & -2 & -3 & -4 \\\\ -5 & -6 & -7 & -8 \\end{bmatrix}$$\n",
    "\n",
    "The Plücker coordinates of these subspaces are given by the determinants of all $2 \\times 2$ submatrices. For $\\Delta W_1$, these are $(1 \\times 6 - 2 \\times 5, 1 \\times 7 - 3 \\times 5, 1 \\times 8 - 4 \\times 5, 2 \\times 7 - 3 \\times 6, 2 \\times 8 - 4 \\times 6, 3 \\times 8 - 4 \\times 7) = (-4, -8, -12, -6, -8, -4)$. Similarly, for $\\Delta W_2$, the Plücker coordinates are $(1, 2, 3, 1, 2, 1)$.\n",
    "\n",
    "The midpoint of the line segment in the Plücker space connecting these two points is simply the arithmetic mean of the two sets of Plücker coordinates. This gives $(-1.5, -3, -4.5, -2.5, -3, -1.5)$.\n",
    "\n",
    "However, as mentioned previously, this point might not satisfy the Plücker relations, which in this case are:\n",
    "\n",
    "\\begin{align*}\n",
    "P_{12}P_{34} - P_{13}P_{24} + P_{14}P_{23} &= 0 \\\\\n",
    "P_{15}P_{26} - P_{16}P_{25} + P_{56}P_{12} &= 0 \\\\\n",
    "P_{25}P_{34} - P_{26}P_{35} + P_{56}P_{13} &= 0 \\\\\n",
    "P_{35}P_{12} - P_{36}P_{15} + P_{56}P_{14} &= 0 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "These equations represent the fact that the Plücker coordinates come from a 2-dimensional subspace of a 4-dimensional space. To find the point in $G(2,4)$ that is closest to the mean point under the Fubini-Study metric, you would need to solve an optimization problem that minimizes the distance from the mean point to $G(2,4)$ subject to these Plücker relations. This is a nontrivial problem that might require numerical methods or specialized algebraic techniques.\n",
    "\n",
    "Once you have the Plücker coordinates of the midpoint, you can find a matrix representation of the corresponding subspace by finding a set of vectors whose $2 \\times 2$ determinants give these Plücker coordinates. Again, this is a nontrivial problem, but in some cases it might be possible to solve it by using techniques from linear algebra or combinatorics.\n",
    "\n",
    "Please note that this is a simplified example for illustrative purposes, and the actual computations in a real-world scenario could be much more complex."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider once more a scenario where we have multiple LoRA models, each adapted for a different task, and we want to update the matrices of a fixed layer of these models. One possible approach is to use the concept of geometric means on the Grassmannian to interpolate between the subspaces spanned by the adapted weights of these models. Here is a rough sketch of how this could be done:\n",
    "\n",
    "1. First, represent the adapted weights of each model as a point in the Grassmannian. This is done by considering the column space (or row space, depending on the specifics of your model) of the weight matrix as a subspace of the whole space of possible weights.\n",
    "\n",
    "2. Use the Plücker embedding to embed these points into a projective space. This gives you a more manageable space to work in.\n",
    "\n",
    "3. Compute the Karcher mean of these points in the projective space. This gives you a new point in projective space that represents the \"average\" of the adapted weights of the models.\n",
    "\n",
    "4. Finally, use the inverse of the Plücker embedding to map this point back to the Grassmannian, giving you a new subspace in the original space of weights.\n",
    "\n",
    "5. The new subspace represents the geometric mean of the adapted weights of the models. You can then use this to update the weights of the layer in question in each of the models.\n",
    "\n",
    "This process allows you to interpolate between the adapted weights of multiple models in a way that respects the underlying geometry of the weight space. This can be a powerful tool for tasks such as ensemble learning, where you want to combine the strengths of multiple models.\n",
    "\n",
    "However, please note that the computation of the Karcher mean can be computationally expensive, and it may not always be well-defined or unique. Furthermore, the process of mapping back and forth between the Grassmannian and projective space can introduce additional complexities.\n",
    "\n",
    "Here is some code to compute the Plücker coordinates for random matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13713356  0.29770262  0.01930738  0.44963994  0.19357615 -0.35692766]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Define the dimensions\n",
    "k, n = 2, 4  \n",
    "\n",
    "# Generate a random k x n matrix X\n",
    "X1 = np.random.rand(k, n)\n",
    "\n",
    "# Compute the Plücker coordinates\n",
    "plucker_coords = []\n",
    "for cols in combinations(range(n), k):\n",
    "    submatrix = X1[:, cols]\n",
    "    if submatrix.shape[0] == submatrix.shape[1]:  # Ensure the submatrix is square\n",
    "        plucker_coords.append(np.linalg.det(submatrix))\n",
    "\n",
    "plucker_coords = np.array(plucker_coords)\n",
    "\n",
    "print(plucker_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plücker coordinates of X1:  [-0.12599737 -0.11151461  0.30825908 -0.02148901  0.47624255  0.36892691\n",
      " -0.029441   -0.20845442 -0.25652258 -0.14683273]\n",
      "Plücker coordinates of X2:  [-0.44510487  0.23468189 -0.16576491  0.43581685  0.06579786 -0.19699786\n",
      "  0.07852637 -0.0959877   0.02136498  0.10559293]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plucker_coordinates(X):\n",
    "    n, m = X.shape\n",
    "    k = min(n, m)\n",
    "    \n",
    "    plucker_coords = []\n",
    "\n",
    "    for rows in itertools.combinations(range(n), k):\n",
    "        for cols in itertools.combinations(range(m), k):\n",
    "            submatrix = X[np.ix_(rows, cols)]\n",
    "            plucker_coords.append(np.linalg.det(submatrix))\n",
    "\n",
    "    return np.array(plucker_coords)\n",
    "\n",
    "# Generate two random matrices\n",
    "n, m = 5, 3\n",
    "X1 = np.random.rand(n, m)\n",
    "X2 = np.random.rand(n, m)\n",
    "\n",
    "# Compute Plücker coordinates\n",
    "plucker_coords1 = plucker_coordinates(X1)\n",
    "plucker_coords2 = plucker_coordinates(X2)\n",
    "\n",
    "# Compute arithmetic mean\n",
    "# mean_coords = (plucker_coords1 + plucker_coords2) / 2\n",
    "\n",
    "print(\"Plücker coordinates of X1: \", plucker_coords1)\n",
    "print(\"Plücker coordinates of X2: \", plucker_coords2)\n",
    "# print(\"Arithmetic mean of Plücker coordinates: \", mean_coords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
